{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dividing and ordering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the dataset contains images that are not relevant (such as drones on the grounds, drones in video games etc) we must first manually check them over, the following section picks random images from the dataset for manual catalogging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterate over the dataset and select a predefined number of random images based on the % of the image the drone takes in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping pos_G3P46281.xml: <bndbox> tag not found.\n",
      "Bins saved to image_bins.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd  # For working with Excel files\n",
    "import random  # For shuffling the list\n",
    "\n",
    "# Configuration\n",
    "xml_folder = \"Drone_TrainSet_XMLs\"  # Folder containing XML files\n",
    "bin_limits = 150  # Maximum files per bin\n",
    "\n",
    "# Initialize bins\n",
    "bins = {\"0-1%\": [], \"2-5%\": [], \"6-10%\": [], \"11-20%\": [], \"21-30%\": [], \"31-40%\": [], \"41-50%\": [], \"51-60%\": [], \"61-70%\": [], \"71-80%\": [], \"81-100%\": []}\n",
    "\n",
    "# Helper function to calculate bounding box area percentage\n",
    "def calculate_bbox_percentage(width, height, xmin, ymin, xmax, ymax):\n",
    "    image_area = width * height\n",
    "    bbox_area = (xmax - xmin) * (ymax - ymin)\n",
    "    return (bbox_area / image_area) * 100\n",
    "\n",
    "# Get list of XML files and shuffle them\n",
    "xml_files = [f for f in os.listdir(xml_folder) if f.endswith(\".xml\")]\n",
    "random.shuffle(xml_files)\n",
    "\n",
    "# Iterate through XML files\n",
    "for xml_file in xml_files:\n",
    "    # Check if all bins are full\n",
    "    if all(len(files) >= bin_limits for files in bins.values()):\n",
    "        print(\"All bins are full. Stopping early.\")\n",
    "        break\n",
    "    \n",
    "    # Parse XML file\n",
    "    tree = ET.parse(os.path.join(xml_folder, xml_file))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Extract image size\n",
    "    size = root.find(\"size\")\n",
    "    if size is None:\n",
    "        print(f\"Skipping {xml_file}: <size> tag not found.\")\n",
    "        continue\n",
    "\n",
    "    width = size.find(\"width\")\n",
    "    height = size.find(\"height\")\n",
    "    if width is None or height is None:\n",
    "        print(f\"Skipping {xml_file}: <width> or <height> tag not found.\")\n",
    "        continue\n",
    "\n",
    "    width = int(width.text)\n",
    "    height = int(height.text)\n",
    "    \n",
    "    # Extract bounding box coordinates\n",
    "    obj = root.find(\"object/bndbox\")\n",
    "    if obj is None:\n",
    "        print(f\"Skipping {xml_file}: <bndbox> tag not found.\")\n",
    "        continue\n",
    "\n",
    "    xmin = obj.find(\"xmin\")\n",
    "    ymin = obj.find(\"ymin\")\n",
    "    xmax = obj.find(\"xmax\")\n",
    "    ymax = obj.find(\"ymax\")\n",
    "    if None in (xmin, ymin, xmax, ymax):\n",
    "        print(f\"Skipping {xml_file}: Bounding box coordinates are missing.\")\n",
    "        continue\n",
    "\n",
    "    xmin = int(xmin.text)\n",
    "    ymin = int(ymin.text)\n",
    "    xmax = int(xmax.text)\n",
    "    ymax = int(ymax.text)\n",
    "    \n",
    "    # Calculate percentage\n",
    "    percentage = calculate_bbox_percentage(width, height, xmin, ymin, xmax, ymax)\n",
    "    \n",
    "    # Determine bin\n",
    "    if percentage <= 1:\n",
    "        bin_name = \"0-1%\"\n",
    "    elif percentage <= 5:\n",
    "        bin_name = \"2-5%\"\n",
    "    elif percentage <= 10:\n",
    "        bin_name = \"6-10%\"\n",
    "    elif percentage <= 20:\n",
    "        bin_name = \"11-20%\"\n",
    "    elif percentage <= 30:\n",
    "        bin_name = \"21-30%\"\n",
    "    elif percentage <= 40:\n",
    "        bin_name = \"31-40%\"\n",
    "    elif percentage <= 50:\n",
    "        bin_name = \"41-50%\"\n",
    "    elif percentage <= 60:\n",
    "        bin_name = \"51-60%\"\n",
    "    elif percentage <= 70:\n",
    "        bin_name = \"61-70%\"\n",
    "    elif percentage <= 80:\n",
    "        bin_name = \"71-80%\"\n",
    "    else:\n",
    "        bin_name = \"81-100%\"\n",
    "    \n",
    "    # Add file to bin if not full\n",
    "    if len(bins[bin_name]) < bin_limits:\n",
    "        bins[bin_name].append(xml_file)\n",
    "\n",
    "# Convert bins to a DataFrame for Excel\n",
    "max_bin_size = max(len(files) for files in bins.values())\n",
    "data = {bin_name: bins[bin_name] + [\"\"] * (max_bin_size - len(bins[bin_name])) for bin_name in bins.keys()}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to Excel\n",
    "output_file = \"image_bins.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Bins saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code in case more images are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping pos_G3P46281.xml: <bndbox> tag not found.\n",
      "New bins saved to new_image_bins.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd  # For working with Excel files\n",
    "\n",
    "# Configuration\n",
    "xml_folder = \"Drone_TrainSet_XMLs\"  \n",
    "previous_excel_file = \"image_bins.xlsx\"  # Excel file from previous run\n",
    "output_excel_file = \"new_image_bins.xlsx\"  # Output Excel file for the new run\n",
    "bin_limits = 150  # Maximum files per bin\n",
    "\n",
    "# Initialize bins\n",
    "bins = {\"0-1%\": [], \"2-5%\": [], \"6-10%\": [], \"11-20%\": [], \"21-30%\": [], \"31-40%\": [], \"41-50%\": [], \"51-60%\": [], \"61-70%\": [], \"71-80%\": [], \"81-100%\": []}\n",
    "\n",
    "# Read filenames from previous Excel file\n",
    "if os.path.exists(previous_excel_file):\n",
    "    prev_data = pd.read_excel(previous_excel_file)\n",
    "    used_files = set(prev_data.values.flatten())  # Collect all filenames into a set\n",
    "    used_files.discard(\"\")  # Remove empty entries\n",
    "else:\n",
    "    used_files = set()\n",
    "\n",
    "# Helper function to calculate bounding box area percentage\n",
    "def calculate_bbox_percentage(width, height, xmin, ymin, xmax, ymax):\n",
    "    image_area = width * height\n",
    "    bbox_area = (xmax - xmin) * (ymax - ymin)\n",
    "    return (bbox_area / image_area) * 100\n",
    "\n",
    "# Iterate through XML files\n",
    "for xml_file in os.listdir(xml_folder):\n",
    "    if not xml_file.endswith(\".xml\") or xml_file in used_files:\n",
    "        continue\n",
    "    \n",
    "    # Check if all bins are full\n",
    "    if all(len(files) >= bin_limits for files in bins.values()):\n",
    "        print(\"All bins are full. Stopping early.\")\n",
    "        break\n",
    "    \n",
    "    # Parse XML file\n",
    "    tree = ET.parse(os.path.join(xml_folder, xml_file))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Extract image size\n",
    "    size = root.find(\"size\")\n",
    "    if size is None:\n",
    "        print(f\"Skipping {xml_file}: <size> tag not found.\")\n",
    "        continue\n",
    "\n",
    "    width = size.find(\"width\")\n",
    "    height = size.find(\"height\")\n",
    "    if width is None or height is None:\n",
    "        print(f\"Skipping {xml_file}: <width> or <height> tag not found.\")\n",
    "        continue\n",
    "\n",
    "    width = int(width.text)\n",
    "    height = int(height.text)\n",
    "    \n",
    "    # Extract bounding box coordinates\n",
    "    obj = root.find(\"object/bndbox\")\n",
    "    if obj is None:\n",
    "        print(f\"Skipping {xml_file}: <bndbox> tag not found.\")\n",
    "        continue\n",
    "\n",
    "    xmin = obj.find(\"xmin\")\n",
    "    ymin = obj.find(\"ymin\")\n",
    "    xmax = obj.find(\"xmax\")\n",
    "    ymax = obj.find(\"ymax\")\n",
    "    if None in (xmin, ymin, xmax, ymax):\n",
    "        print(f\"Skipping {xml_file}: Bounding box coordinates are missing.\")\n",
    "        continue\n",
    "\n",
    "    xmin = int(xmin.text)\n",
    "    ymin = int(ymin.text)\n",
    "    xmax = int(xmax.text)\n",
    "    ymax = int(ymax.text)\n",
    "    \n",
    "    # Calculate percentage\n",
    "    percentage = calculate_bbox_percentage(width, height, xmin, ymin, xmax, ymax)\n",
    "    \n",
    "    # Determine bin\n",
    "    if percentage <= 1:\n",
    "        bin_name = \"0-1%\"\n",
    "    elif percentage <= 5:\n",
    "        bin_name = \"2-5%\"\n",
    "    elif percentage <= 10:\n",
    "        bin_name = \"6-10%\"\n",
    "    elif percentage <= 20:\n",
    "        bin_name = \"11-20%\"\n",
    "    elif percentage <= 30:\n",
    "        bin_name = \"21-30%\"\n",
    "    elif percentage <= 40:\n",
    "        bin_name = \"31-40%\"\n",
    "    elif percentage <= 50:\n",
    "        bin_name = \"41-50%\"\n",
    "    elif percentage <= 60:\n",
    "        bin_name = \"51-60%\"\n",
    "    elif percentage <= 70:\n",
    "        bin_name = \"61-70%\"\n",
    "    elif percentage <= 80:\n",
    "        bin_name = \"71-80%\"\n",
    "    else:\n",
    "        bin_name = \"81-100%\"\n",
    "    \n",
    "    # Add file to bin if not full\n",
    "    if len(bins[bin_name]) < bin_limits:\n",
    "        bins[bin_name].append(xml_file)\n",
    "\n",
    "# Convert bins to a DataFrame for Excel\n",
    "max_bin_size = max(len(files) for files in bins.values())\n",
    "data = {bin_name: bins[bin_name] + [\"\"] * (max_bin_size - len(bins[bin_name])) for bin_name in bins.keys()}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"New bins saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating folders for different distances after manual cataloging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "Available bins: 0-1%, 2-5%, 6-10%, 11-20%, 21-30%, 31-40%, 41-50%, 50%+\n",
      "Files have been copied successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Configuration\n",
    "excel_file = \"image_bins.xlsx\"  # Path to the Excel file\n",
    "image_folder = \"Drone_TrainSet\"  # Folder containing all images\n",
    "xml_folder = \"Drone_TrainSet_XMLs\"  # Folder containing all XML files\n",
    "output_image_folder = \"output_images\"  # Destination for categorized images\n",
    "output_xml_folder = \"output_xml\"  # Destination for categorized XML files\n",
    "\n",
    "# Function to copy files to the appropriate bin folders\n",
    "def copy_files_to_bins(bins_to_process):\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    for bin_name in bins_to_process:\n",
    "        if bin_name not in df.columns:\n",
    "            print(f\"Bin '{bin_name}' does not exist in the Excel file. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Create output directories for images and XMLs\n",
    "        image_bin_folder = os.path.join(output_image_folder, bin_name)\n",
    "        xml_bin_folder = os.path.join(output_xml_folder, bin_name)\n",
    "        os.makedirs(image_bin_folder, exist_ok=True)\n",
    "        os.makedirs(xml_bin_folder, exist_ok=True)\n",
    "        \n",
    "        # Process files in the current bin\n",
    "        for filename in df[bin_name].dropna():\n",
    "            # Prepare file paths\n",
    "            base_filename = filename.replace(\".xml\", \"\")  # Remove .xml only for image names\n",
    "            image_file = os.path.join(image_folder, f\"{base_filename}.jpg\")\n",
    "            xml_file = os.path.join(xml_folder, filename)  # Keep .xml for XML file handling\n",
    "\n",
    "            # Check if files exist\n",
    "            if os.path.exists(image_file):\n",
    "                shutil.copy(image_file, image_bin_folder)\n",
    "            else:\n",
    "                print(f\"Image file not found: {image_file}\")\n",
    "\n",
    "            if os.path.exists(xml_file):\n",
    "                shutil.copy(xml_file, xml_bin_folder)\n",
    "            else:\n",
    "                print(f\"XML file not found: {xml_file}\")\n",
    "\n",
    "    print(\"Files have been copied successfully.\")\n",
    "\n",
    "# Dynamically select bins to process\n",
    "if __name__ == \"__main__\":\n",
    "    # List all available bins in the Excel file\n",
    "    df = pd.read_excel(excel_file)\n",
    "    print(\"hi\")\n",
    "    available_bins = df.columns.tolist()\n",
    "    print(\"Available bins:\", \", \".join(available_bins))\n",
    "\n",
    "    # Get input for bins to process\n",
    "    bins_to_process = input(\"Enter the bins to process (comma-separated): \").split(\",\")\n",
    "    bins_to_process = [bin_name.strip() for bin_name in bins_to_process if bin_name.strip()]\n",
    "\n",
    "    # Copy files to the selected bins\n",
    "    copy_files_to_bins(bins_to_process)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we used a different dataset for optimization so no need to divide this into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Configuration\n",
    "output_image_folder = \"output_images\"  # Folder containing bin folders for images\n",
    "output_xml_folder = \"output_xml\"  # Folder containing bin folders for XML files\n",
    "test_folder = \"test\"  # Folder for training data\n",
    "test_split =1 
     
    "\n",
    "def split_data():\n",
    "    # Create train, validation, and test folders with subfolders for images and XMLs\n",
    
    "    test_image_folder = os.path.join(test_folder, \"images\")\n",
    "    test_xml_folder = os.path.join(test_folder, \"xml\")\n",
    "    \n",
    "    
    "    os.makedirs(test_image_folder, exist_ok=True)\n",
    "    os.makedirs(test_xml_folder, exist_ok=True)\n",
    "    \n",
    "    # Process each bin\n",
    "    for bin_name in os.listdir(output_image_folder):\n",
    "        image_bin_path = os.path.join(output_image_folder, bin_name)\n",
    "        xml_bin_path = os.path.join(output_xml_folder, bin_name)\n",
    "        \n",
    "        # Ensure corresponding bin folders exist for both images and XMLs\n",
    "        if not os.path.isdir(image_bin_path) or not os.path.isdir(xml_bin_path):\n",
    "            print(f\"Skipping bin '{bin_name}' as it does not exist in both image and XML folders.\")\n",
    "            continue\n",
    "        \n",
    "        # List all files in the image bin\n",
    "        image_files = [f for f in os.listdir(image_bin_path) if f.endswith(\".jpg\")]\n",
    "        total_files = len(image_files)\n",
    "        \n",
    "        if total_files == 0:\n",
    "            print(f\"No images found in bin '{bin_name}'. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        
    "        random.shuffle(image_files)\n",
    "        
    "        test_files = image_files[train_size + val_size:]\n",
    "        \n",
    "        # Copy files to train, validation, and test folders\n",
    "        for file_list, dest_image_folder, dest_xml_folder in [\n",
    "            
    "            (test_files, test_image_folder, test_xml_folder),\n",
    "        ]:\n",
    "            for image_file in file_list:\n",
    "                # Corresponding XML file\n",
    "                base_name = os.path.splitext(image_file)[0]\n",
    "                xml_file = f\"{base_name}.xml\"\n",
    "                \n",
    "                # Source paths\n",
    "                image_source_path = os.path.join(image_bin_path, image_file)\n",
    "                xml_source_path = os.path.join(xml_bin_path, xml_file)\n",
    "                \n",
    "                # Destination paths\n",
    "                image_dest_path = os.path.join(dest_image_folder, image_file)\n",
    "                xml_dest_path = os.path.join(dest_xml_folder, xml_file)\n",
    "                \n",
    "                # Copy files\n",
    "                if os.path.exists(image_source_path):\n",
    "                    shutil.copy(image_source_path, image_dest_path)\n",
    "                else:\n",
    "                    print(f\"Image file not found: {image_source_path}\")\n",
    "                \n",
    "                if os.path.exists(xml_source_path):\n",
    "                    shutil.copy(xml_source_path, xml_dest_path)\n",
    "                else:\n",
    "                    print(f\"XML file not found: {xml_source_path}\")\n",
    "        \n",
    "        print(f\"Processed bin '{bin_name}': {len(train_files)} train files, {len(val_files)} validation files, {len(test_files)} test files.\")\n",
    "\n",
    "    print(\"Data splitting completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changing format for yolo (xml->txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. Labels saved in train/labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Paths to your folders\n",
    "xml_folder = \"train/xml\"  # need to manually change the folder to the relevant - test,train or validation\n",
    "output_labels_folder = \"train/labels\"  # same as above\n",
    "os.makedirs(output_labels_folder, exist_ok=True)\n",
    "\n",
    "# Function to convert XML to YOLO format\n",
    "def convert_xml_to_yolo(xml_file, output_folder):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get image dimensions\n",
    "    size = root.find(\"size\")\n",
    "    width = int(size.find(\"width\").text)\n",
    "    height = int(size.find(\"height\").text)\n",
    "\n",
    "    label_lines = []\n",
    "\n",
    "    # Iterate over object elements\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        class_id = 0 if class_name == \"drone\" else -1  # Map class names to IDs\n",
    "\n",
    "        # Skip objects that aren't drones\n",
    "        if class_id == -1:\n",
    "            continue\n",
    "\n",
    "        # Get bounding box coordinates\n",
    "        bndbox = obj.find(\"bndbox\")\n",
    "        xmin = int(bndbox.find(\"xmin\").text)\n",
    "        ymin = int(bndbox.find(\"ymin\").text)\n",
    "        xmax = int(bndbox.find(\"xmax\").text)\n",
    "        ymax = int(bndbox.find(\"ymax\").text)\n",
    "\n",
    "        # Convert to YOLO format (normalized)\n",
    "        x_center = ((xmin + xmax) / 2) / width\n",
    "        y_center = ((ymin + ymax) / 2) / height\n",
    "        bbox_width = (xmax - xmin) / width\n",
    "        bbox_height = (ymax - ymin) / height\n",
    "\n",
    "        # Append to label lines\n",
    "        label_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\")\n",
    "\n",
    "    # Write to a .txt file\n",
    "    output_file = os.path.join(output_folder, os.path.splitext(os.path.basename(xml_file))[0] + \".txt\")\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(label_lines))\n",
    "\n",
    "# Convert all XML files in the folder\n",
    "for xml_file in os.listdir(xml_folder):\n",
    "    if xml_file.endswith(\".xml\"):\n",
    "        convert_xml_to_yolo(os.path.join(xml_folder, xml_file), output_labels_folder)\n",
    "\n",
    "print(f\"Conversion completed. Labels saved in {output_labels_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bird dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "divide into % of whole pic as we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorization Complete!\n",
      "0-1%: 72 images\n",
      "2-5%: 87 images\n",
      "6-10%: 56 images\n",
      "11-20%: 54 images\n",
      "21-30%: 31 images\n",
      "31-40%: 13 images\n",
      "41-50%: 2 images\n",
      "50%+: 2 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Directories\n",
    "image_folder = r\"birds_dataset\\all\\images\"  # Path to folder containing image files\n",
    "txt_folder = r\"\\birds_dataset\\all\\labels\"  # Path to folder containing txt annotation files\n",
    "output_folder = \"bird_output\"  # Output directory for categorized folders\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Size categories (percentage ranges)\n",
    "size_categories = [\n",
    "    (\"0-1%\", 0, 0.01),\n",
    "    (\"2-5%\", 0.02, 0.05),\n",
    "    (\"6-10%\", 0.06, 0.10),\n",
    "    (\"11-20%\", 0.11, 0.20),\n",
    "    (\"21-30%\", 0.21, 0.30),\n",
    "    (\"31-40%\", 0.31, 0.40),\n",
    "    (\"41-50%\", 0.41, 0.50),\n",
    "    (\"50%+\", 0.51, 1.00),\n",
    "]\n",
    "\n",
    "# Dictionary to track counts for each category\n",
    "category_counts = {cat[0]: 0 for cat in size_categories}\n",
    "\n",
    "# Process each annotation file\n",
    "for txt_file in os.listdir(txt_folder):\n",
    "    if not txt_file.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    txt_path = os.path.join(txt_folder, txt_file)\n",
    "    image_name = txt_file.replace(\".txt\", \".jpg\")\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file not found for annotation: {txt_file}\")\n",
    "        continue\n",
    "\n",
    "    # Read the annotation file\n",
    "    with open(txt_path, \"r\") as file:\n",
    "        annotations = file.readlines()\n",
    "\n",
    "    # Calculate total bounding box size percentage for the image\n",
    "    image_size_percentage = 0\n",
    "    for line in annotations:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            print(f\"Invalid annotation in {txt_file}: {line}\")\n",
    "            continue\n",
    "\n",
    "        # Parse YOLO format annotation\n",
    "        _, x_center, y_center, width, height = map(float, parts)\n",
    "        box_area = width * height  # Relative area\n",
    "        image_size_percentage += box_area\n",
    "\n",
    "    # Determine the category based on bounding box size percentage\n",
    "    for category_name, lower, upper in size_categories:\n",
    "        if lower <= image_size_percentage <= upper:\n",
    "            # Create the category folder if it doesn't exist\n",
    "            category_image_folder = os.path.join(output_folder, category_name, \"images\")\n",
    "            category_txt_folder = os.path.join(output_folder, category_name, \"annotations\")\n",
    "            os.makedirs(category_image_folder, exist_ok=True)\n",
    "            os.makedirs(category_txt_folder, exist_ok=True)\n",
    "\n",
    "            # Copy the image and annotation to the category folder\n",
    "            shutil.copy(image_path, category_image_folder)\n",
    "            shutil.copy(txt_path, category_txt_folder)\n",
    "\n",
    "            # Increment the count for this category\n",
    "            category_counts[category_name] += 1\n",
    "            break\n",
    "\n",
    "# Print summary of results\n",
    "print(\"Categorization Complete!\")\n",
    "for category_name, count in category_counts.items():\n",
    "    print(f\"{category_name}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed folder '0-1%': 50 train files, 7 validation files, 15 test files.\n",
      "Processed folder '11-20%': 37 train files, 5 validation files, 12 test files.\n",
      "Processed folder '2-5%': 60 train files, 8 validation files, 19 test files.\n",
      "Processed folder '21-30%': 21 train files, 3 validation files, 7 test files.\n",
      "Processed folder '31-40%': 9 train files, 1 validation files, 3 test files.\n",
      "Processed folder '41-50%': 1 train files, 0 validation files, 1 test files.\n",
      "Processed folder '50%+': 1 train files, 0 validation files, 1 test files.\n",
      "Processed folder '6-10%': 39 train files, 5 validation files, 12 test files.\n",
      "Data splitting completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Configuration\n",
    "base_folder = \"bird_output\"  # Folder containing percentage folders (0-1%, 2-5%, ...)\n",
    "train_folder = \"train\"  # Folder for training data\n",
    "val_folder = \"validation\"  # Folder for validation data\n",
    "test_folder = \"test\"  # Folder for test data\n",
    "train_split = 0.7  # Proportion of files to include in the training set\n",
    "val_split = 0.1  # Proportion of files to include in the validation set\n",
    "\n",
    "def split_data():\n",
    "    # Create train, validation, and test folders with subfolders for images and TXT annotations\n",
    "    train_image_folder = os.path.join(train_folder, \"images\")\n",
    "    train_txt_folder = os.path.join(train_folder, \"annotations\")\n",
    "    val_image_folder = os.path.join(val_folder, \"images\")\n",
    "    val_txt_folder = os.path.join(val_folder, \"annotations\")\n",
    "    test_image_folder = os.path.join(test_folder, \"images\")\n",
    "    test_txt_folder = os.path.join(test_folder, \"annotations\")\n",
    "    \n",
    "    os.makedirs(train_image_folder, exist_ok=True)\n",
    "    os.makedirs(train_txt_folder, exist_ok=True)\n",
    "    os.makedirs(val_image_folder, exist_ok=True)\n",
    "    os.makedirs(val_txt_folder, exist_ok=True)\n",
    "    os.makedirs(test_image_folder, exist_ok=True)\n",
    "    os.makedirs(test_txt_folder, exist_ok=True)\n",
    "    \n",
    "    # Process each percentage folder\n",
    "    for size_folder in os.listdir(base_folder):\n",
    "        size_path = os.path.join(base_folder, size_folder)\n",
    "        image_folder = os.path.join(size_path, \"images\")\n",
    "        txt_folder = os.path.join(size_path, \"annotations\")\n",
    "        \n",
    "        # Ensure both images and annotations folders exist\n",
    "        if not os.path.isdir(image_folder) or not os.path.isdir(txt_folder):\n",
    "            print(f\"Skipping folder '{size_folder}' as it does not contain both images and annotations.\")\n",
    "            continue\n",
    "        \n",
    "        # List all files in the image folder\n",
    "        image_files = [f for f in os.listdir(image_folder) if f.endswith(\".jpg\")]\n",
    "        total_files = len(image_files)\n",
    "        \n",
    "        if total_files == 0:\n",
    "            print(f\"No images found in folder '{size_folder}'. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Shuffle and split the files into train, validation, and test sets\n",
    "        random.shuffle(image_files)\n",
    "        train_size = int(total_files * train_split)\n",
    "        val_size = int(total_files * val_split)\n",
    "        train_files = image_files[:train_size]\n",
    "        val_files = image_files[train_size:train_size + val_size]\n",
    "        test_files = image_files[train_size + val_size:]\n",
    "        \n",
    "        # Copy files to train, validation, and test folders without overwriting\n",
    "        for file_list, dest_image_folder, dest_txt_folder in [\n",
    "            (train_files, train_image_folder, train_txt_folder),\n",
    "            (val_files, val_image_folder, val_txt_folder),\n",
    "            (test_files, test_image_folder, test_txt_folder),\n",
    "        ]:\n",
    "            for image_file in file_list:\n",
    "                # Corresponding TXT file\n",
    "                base_name = os.path.splitext(image_file)[0]\n",
    "                txt_file = f\"{base_name}.txt\"\n",
    "                \n",
    "                # Source paths\n",
    "                image_source_path = os.path.join(image_folder, image_file)\n",
    "                txt_source_path = os.path.join(txt_folder, txt_file)\n",
    "                \n",
    "                # Destination paths\n",
    "                image_dest_path = os.path.join(dest_image_folder, image_file)\n",
    "                txt_dest_path = os.path.join(dest_txt_folder, txt_file)\n",
    "                \n",
    "                # Copy files only if they don't already exist\n",
    "                if os.path.exists(image_source_path) and not os.path.exists(image_dest_path):\n",
    "                    shutil.copy(image_source_path, image_dest_path)\n",
    "                elif os.path.exists(image_dest_path):\n",
    "                    print(f\"Image file already exists: {image_dest_path}\")\n",
    "                \n",
    "                if os.path.exists(txt_source_path) and not os.path.exists(txt_dest_path):\n",
    "                    shutil.copy(txt_source_path, txt_dest_path)\n",
    "                elif os.path.exists(txt_dest_path):\n",
    "                    print(f\"TXT file already exists: {txt_dest_path}\")\n",
    "        \n",
    "        print(f\"Processed folder '{size_folder}': {len(train_files)} train files, {len(val_files)} validation files, {len(test_files)} test files.\")\n",
    "\n",
    "    print(\"Data splitting completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the datasets come from different sources, we need to change annotations for birds from 0(used for drones) to 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations updated. Updated files saved in validation\\labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Configuration\n",
    "annotations_folder = r\"validation\\annotations\"  # Folder containing annotation files\n",
    "output_folder = r\"validation\\labels\"  # Output folder for updated annotation files\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each annotation file\n",
    "\n",
    "for txt_file in os.listdir(annotations_folder):\n",
    "    if not txt_file.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    txt_path = os.path.join(annotations_folder, txt_file)\n",
    "\n",
    "    # Read the annotation file\n",
    "    with open(txt_path, \"r\") as file:\n",
    "        annotations = file.readlines()\n",
    "\n",
    "    # Update the annotation file\n",
    "    updated_annotations = []\n",
    "    for line in annotations:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            print(f\"Invalid annotation in {txt_file}: {line}\")\n",
    "            continue\n",
    "\n",
    "        # Parse YOLO format annotation\n",
    "        class_id, x_center, y_center, width, height = map(float, parts)\n",
    "        updated_annotations.append(f\"1 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "    # Write the updated annotation to a new file\n",
    "    output_file = os.path.join(output_folder, txt_file)\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(updated_annotations))\n",
    "\n",
    "print(f\"Annotations updated. Updated files saved in {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the size of test train and validation folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "Number of images: 1050\n",
      "Number of annotation files: 218\n",
      "\n",
      "Validation Data:\n",
      "Number of images: 145\n",
      "Number of annotation files: 29\n",
      "\n",
      "Test Data:\n",
      "Number of images: 313\n",
      "Number of annotation files: 70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "train_folder = \"train\"  # Folder for training data\n",
    "val_folder = \"validation\"  # Folder for validation data\n",
    "test_folder = \"test\"  # Folder for test data\n",
    "\n",
    "def count_files(folder):\n",
    "    image_folder = os.path.join(folder, \"images\")\n",
    "    txt_folder = os.path.join(folder, \"annotations\")\n",
    "\n",
    "    num_images = len([f for f in os.listdir(image_folder) if f.endswith(\".jpg\")])\n",
    "    num_txt_files = len([f for f in os.listdir(txt_folder) if f.endswith(\".txt\")])\n",
    "\n",
    "    return num_images, num_txt_files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_images, train_txt = count_files(train_folder)\n",
    "    val_images, val_txt = count_files(val_folder)\n",
    "    test_images, test_txt = count_files(test_folder)\n",
    "\n",
    "    print(\"Train Data:\")\n",
    "    print(f\"Number of images: {train_images}\")\n",
    "    print(f\"Number of annotation files: {train_txt}\")\n",
    "\n",
    "    print(\"\\nValidation Data:\")\n",
    "    print(f\"Number of images: {val_images}\")\n",
    "    print(f\"Number of annotation files: {val_txt}\")\n",
    "\n",
    "    print(\"\\nTest Data:\")\n",
    "    print(f\"Number of images: {test_images}\")\n",
    "    print(f\"Number of annotation files: {test_txt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
